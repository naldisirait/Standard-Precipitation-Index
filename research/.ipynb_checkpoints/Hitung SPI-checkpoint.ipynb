{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0492f9-7b38-4474-9005-2c59e6c581f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "from scipy import stats as st\n",
    "from standard_precip import spi\n",
    "import jenkspy\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59458d2-5289-4245-9127-2bfdc8d0e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    \"\"\"\n",
    "    Function to load nc dataset\n",
    "    Args:\n",
    "        path: path to the dataset, includes filename\n",
    "    Returns:\n",
    "        dataset: a xarray dataset\n",
    "    \"\"\"\n",
    "    dataset = xr.open_dataset(path)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fba886a-da12-4588-aac1-60094354bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"C:/Users/62812/Documents/Kerjaan Meteorologi/Data/pr_CESM2-WACCM_ssp245.nc\"\n",
    "#load dataset\n",
    "dataset = load_data(path_data)\n",
    "\n",
    "#create monthly precip\n",
    "monthly_precip = dataset['pr'].resample(time='1ME').sum(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f8e37a-375a-4504-bbb6-9597fc03cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_val = monthly_precip.values\n",
    "latitude = dataset['lat'].values\n",
    "longitude = dataset['lon'].values\n",
    "data_time = monthly_precip.indexes['time'].to_datetimeindex()\n",
    "\n",
    "spi_scale = [3,6]\n",
    "spi_result = {}\n",
    "for sc in spi_scale: \n",
    "    spi_val = np.zeros(prec_val.shape)\n",
    "    for x in range(spi_val.shape[1]):\n",
    "        for y in range(spi_val.shape[2]):\n",
    "            precip_grid = prec_val[:,x,y]\n",
    "            if np.isnan(np.sum(precip_grid)) != True:\n",
    "                df_precip = pd.DataFrame({\"Date\": data_time,\"precip\":precip_grid})\n",
    "                spi_prc = spi.SPI()\n",
    "                spi_grid = spi_prc.calculate(df_precip, 'Date', 'precip', freq = 'M', scale = sc, fit_type =\"lmom\", dist_type=\"gam\")\n",
    "                spi_grid_val = spi_grid['precip_scale_{}_calculated_index'.format(sc)].values\n",
    "                spi_val[:,x,y] = spi_grid_val\n",
    "            else:\n",
    "                spi_val[:,x,y] = np.nan\n",
    "    spi_result[str(sc)] = spi_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81310fe-cb14-4548-a19e-2810b3f4c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_drought(data_spi,skala):\n",
    "    if skala > 0:\n",
    "        data_nan = skala - 1\n",
    "    elif skala == 0:\n",
    "        data_nan = 0\n",
    "    spi_val = data_spi[data_nan:,:,:]\n",
    "    \n",
    "    shape_1 = spi_val.shape[1]\n",
    "    shape_2 = spi_val.shape[2]\n",
    "    \n",
    "    prob_md = np.zeros((shape_1,shape_2)) # md (moderate drought)\n",
    "    prob_sd = np.zeros((shape_1,shape_2)) # sd (severe drought)\n",
    "    prob_vsd = np.zeros((shape_1,shape_2)) # vsd (very severe drought)\n",
    "    \n",
    "    for x in range(shape_1):\n",
    "        for y in range(shape_2):\n",
    "            if np.isnan(np.sum(spi_val[:,x,y])) != True:\n",
    "                prob_md[x,y] = 100 * len(np.where((spi_val[:,x,y]<-1) & (spi_val[:,x,y]>-1.49))[0])/len(spi_val)\n",
    "                prob_sd[x,y] = 100 * len(np.where((spi_val[:,x,y]<-1.5) & (spi_val[:,x,y]>-1.99))[0])/len(spi_val)\n",
    "                prob_vsd[x,y] = 100 * len(np.where(spi_val[:,x,y]<-2)[0])/len(spi_val)\n",
    "            else:\n",
    "                prob_md[x,y] = np.nan\n",
    "                prob_sd[x,y] = np.nan\n",
    "                prob_vsd[x,y] = np.nan\n",
    "    return prob_md,prob_sd,prob_vsd\n",
    "               \n",
    "prob_result = {}\n",
    "for sc in spi_scale:\n",
    "    prob_md,prob_sd,prob_vsd = prob_drought(spi_result[str(sc)],sc)\n",
    "    prob_drougth_severity = {\"moderate\" : prob_md, \"severe\":prob_sd, \"very severe\":prob_vsd}\n",
    "    prob_result[str(sc)] = prob_drougth_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e200da53-d1b3-44c2-b082-8b177419066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Percentage of Occurance (PoF)\n",
    "# PoF = {\"moderate\" : [6.44, 7.71, 9.07],\n",
    "#        \"severe\" : [3.75, 3.55\n",
    "\n",
    "#Percentage of Occurance (PoF)\n",
    "PoF = {\"moderate\" : [9, 10, 11],\n",
    "       \"severe\" : [3.5, 4.5, 5.5],\n",
    "       \"very severe\" : [1.5, 2, 2.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8dd539e-badc-4e84-a826-53b0508cf0c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dhi_spi \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sc \u001b[38;5;129;01min\u001b[39;00m prob_result:\n\u001b[1;32m----> 3\u001b[0m     md_val \u001b[38;5;241m=\u001b[39m \u001b[43mprob_result\u001b[49m\u001b[43m[\u001b[49m\u001b[43msc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m     sd_val \u001b[38;5;241m=\u001b[39m prob_result[sc][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m     vsd_val \u001b[38;5;241m=\u001b[39m prob_result[sc][\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "dhi_spi = {}\n",
    "for sc in prob_result:\n",
    "    md_val = prob_result[sc]['moderate']\n",
    "    sd_val = prob_result[sc]['severe']\n",
    "    vsd_val = prob_result[sc]['very severe']\n",
    "\n",
    "    prob_md = prob_result[sc]['moderate'].copy()\n",
    "    prob_sd = prob_result[sc]['moderate'].copy()\n",
    "    prob_vsd = prob_result[sc]['moderate'].copy()\n",
    "    \n",
    "    rating_md = PoF[\"moderate\"]\n",
    "    rating_sd = PoF[\"severe\"]\n",
    "    rating_vsd = PoF[\"very severe\"]\n",
    "    \n",
    "    prob_md[np.where(md_val<= rating_md[0])] = 1\n",
    "    prob_md[np.where((md_val > rating_md[0]) & (md_val <= rating_md[1]))] = 2\n",
    "    prob_md[np.where((md_val > rating_md[1]) & (md_val <= rating_md[2]))] = 3\n",
    "    prob_md[np.where(md_val>rating_md[2])] = 4\n",
    "    \n",
    "    prob_sd[np.where(sd_val<=rating_sd[0])] = 1\n",
    "    prob_sd[np.where((sd_val > rating_sd[0]) & (sd_val <= rating_sd[1]))] = 2\n",
    "    prob_sd[np.where((sd_val > rating_sd[1]) & (sd_val <= rating_sd[2]))] = 3\n",
    "    prob_sd[np.where(sd_val>rating_sd[2])] = 4\n",
    "\n",
    "    prob_vsd[np.where(vsd_val<=rating_vsd[0])] = 1\n",
    "    prob_vsd[np.where((vsd_val > rating_vsd[0]) & (vsd_val <= rating_vsd[1]))] = 2\n",
    "    prob_vsd[np.where((vsd_val > rating_vsd[1]) & (vsd_val <= rating_vsd[2]))] = 3\n",
    "    prob_vsd[np.where(vsd_val>rating_vsd[2])] = 4\n",
    "    \n",
    "    dhi = (prob_md * 1) + (prob_sd * 2) + (prob_vsd * 3)\n",
    "    dhi_spi[sc] = dhi\n",
    "\n",
    "def make_nc2d(data,lon,lat,variable,output_name):\n",
    "    encode = {variable: {\"zlib\":True, \"complevel\":9}}\n",
    "    dxr = xr.Dataset(\n",
    "    {variable: ((\"longitude\", \"latitude\"), data)},\n",
    "    coords={\n",
    "        \"longitude\": lon,\n",
    "        \"latitude\": lat,\n",
    "        })\n",
    "    dxr.to_netcdf(\"{}.nc\".format(output_name),encoding = encode)\n",
    "    \n",
    "#Funtion to make nc file\n",
    "def make_nc3D(data,time,lon,lat,variable,output_name):\n",
    "    encode = {variable: {\"zlib\":True, \"complevel\":9}}\n",
    "    dxr = xr.Dataset(\n",
    "    {\"{}\".format(variable): ((\"time\",\"longitude\", \"latitude\"), data)},\n",
    "    coords={\n",
    "        \"time\" : time,\n",
    "        \"longitude\": lon,\n",
    "        \"latitude\": lat,\n",
    "        })\n",
    "    dxr.to_netcdf(\"{}.nc\".format(output_name),encoding = encode)\n",
    "    \n",
    "for sc in prob_result:\n",
    "    make_nc3D(spi_result[sc],data_time,longitude,latitude,\"spi\",\"SPI {} - {}\".format(sc,file_name[:-3]))\n",
    "    make_nc2d(dhi_spi[sc],longitude,latitude,\"dhi\",\"DHI SPI {} - {}\".format(sc,file_name[:-3]))\n",
    "    make_nc2d(prob_result[sc][0],longitude,latitude,\"prob\",\"Probability SPI {} MD- {}\".format(sc,file_name[:-3]))\n",
    "    make_nc2d(prob_result[sc][1],longitude,latitude,\"prob\",\"Probability SPI {} SD- {}\".format(sc,file_name[:-3]))\n",
    "    make_nc2d(prob_result[sc][2],longitude,latitude,\"prob\",\"Probability SPI {} VSD- {}\".format(sc,file_name[:-3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
